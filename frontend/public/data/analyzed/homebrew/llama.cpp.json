{
  "ecosystem": "homebrew",
  "name": "llama.cpp",
  "description": "LLM inference in C/C++",
  "version": "7580",
  "homepage": "https://github.com/ggml-org/llama.cpp",
  "repository": {
    "platform": "github",
    "owner": "ggml-org",
    "repo": "llama",
    "subpath": null
  },
  "install_count_30d": 19868,
  "data_availability": "repo_not_found",
  "unavailable_reason": "Repository ggml-org/llama not accessible (may be private, deleted, or renamed)",
  "scores": null,
  "github_data": null,
  "llm_assessments": null,
  "analysis_summary": {
    "data_availability": "repo_not_found",
    "unavailable_reason": "Repository ggml-org/llama not accessible (may be private, deleted, or renamed)"
  },
  "analyzed_at": "2025-12-31T00:46:51.197420Z",
  "data_fetched_at": "2025-12-31T00:46:51.197422Z"
}