{
  "ecosystem": "pypi",
  "name": "autoevals",
  "description": "Universal library for evaluating AI models",
  "version": "0.0.130",
  "homepage": "https://www.braintrustdata.com",
  "repository": {
    "platform": "github",
    "owner": "braintrustdata",
    "repo": "autoevals",
    "subpath": null
  },
  "install_count_30d": 776056,
  "data_availability": "available",
  "unavailable_reason": null,
  "scores": {
    "overall": 74.5,
    "grade": "C",
    "percentile": null,
    "risk_tier": "conditional",
    "update_urgency": "low",
    "confidence": "medium",
    "confidence_factors": [
      "No LLM assessment available"
    ],
    "project_age_band": "established",
    "security": {
      "score": 85.0,
      "weight": 30,
      "key_factors": []
    },
    "maintenance": {
      "score": 66.48548895221325,
      "weight": 25,
      "key_factors": []
    },
    "community": {
      "score": 77.0,
      "weight": 15,
      "key_factors": []
    },
    "bus_factor": {
      "score": 67.36,
      "weight": 10,
      "key_factors": []
    },
    "documentation": {
      "score": 57.5,
      "weight": 10,
      "key_factors": []
    },
    "stability": {
      "score": 83.0,
      "weight": 10,
      "key_factors": []
    }
  },
  "github_data": {
    "repo": {
      "owner": "braintrustdata",
      "name": "autoevals",
      "description": "AutoEvals is a tool for quickly and easily evaluating AI model outputs using best practices.",
      "stars": 767,
      "forks": 50,
      "open_issues": 19,
      "watchers": 767,
      "created_at": "2023-07-11T06:25:52Z",
      "updated_at": "2026-01-11T15:00:35Z",
      "pushed_at": "2026-01-01T21:59:27Z",
      "default_branch": "main",
      "license": "MIT",
      "language": "Python",
      "topics": [],
      "is_archived": false,
      "is_fork": false,
      "has_discussions": false,
      "is_deprecated": false
    },
    "contributors": {
      "total_contributors": 23,
      "active_contributors_6mo": 5,
      "top_contributor_pct": 60.5,
      "contributors_over_5pct": 2,
      "contributors_prev_6mo": 9,
      "contributor_trend": "declining",
      "first_time_contributors_6mo": 2,
      "contributor_entropy": 2.17
    },
    "commits": {
      "last_commit_date": "2025-12-30T21:54:31Z",
      "commits_last_6mo": 7,
      "commits_last_year": 35
    },
    "issues": {
      "open_issues": 10,
      "closed_issues_6mo": 0,
      "avg_response_time_hours": null,
      "avg_close_time_hours": null,
      "good_first_issue_count": 0,
      "regression_issue_count": 0
    },
    "prs": {
      "open_prs": 9,
      "merged_prs_6mo": 8,
      "closed_prs_6mo": 10,
      "stale_prs": 7,
      "avg_merge_time_hours": null
    },
    "releases": {
      "total_releases": 0,
      "releases_last_year": 0,
      "last_release_date": null,
      "latest_version": null,
      "has_signed_releases": false,
      "prerelease_ratio": 0.0
    },
    "security": {
      "has_security_md": false,
      "has_security_policy": false,
      "signed_commits_pct": 54.0,
      "has_dependabot": false,
      "has_codeql": false,
      "has_security_ci": false,
      "has_snyk": false,
      "has_renovate": false,
      "has_trivy": false,
      "has_semgrep": false,
      "slsa_level": null,
      "has_sigstore": false,
      "has_sbom": false,
      "has_reproducible_builds": false,
      "known_cves": 0,
      "vulnerable_deps": 0,
      "cve_history": {
        "total_cves": 0,
        "cves": [],
        "avg_days_to_patch": null,
        "has_unpatched": false
      }
    },
    "files": {
      "has_readme": true,
      "readme_size_bytes": 15117,
      "has_license": true,
      "has_changelog": true,
      "has_contributing": false,
      "has_code_of_conduct": false,
      "has_codeowners": false,
      "has_governance": false,
      "has_docs_dir": false,
      "has_examples_dir": false,
      "has_tests_dir": false,
      "has_ci_config": true,
      "has_issue_templates": false,
      "has_pr_template": false,
      "has_funding": false
    },
    "ci": {
      "has_github_actions": true,
      "workflow_count": 5,
      "recent_runs_pass_rate": 100.0,
      "has_tests_workflow": true,
      "has_lint_workflow": true,
      "has_security_workflow": false,
      "has_release_workflow": false,
      "has_multi_platform": false
    }
  },
  "llm_assessments": {},
  "supply_chain": null,
  "aggregator_data": {
    "scorecard": null,
    "project_metrics": {
      "stars": 766,
      "forks": 50,
      "open_issues": 19,
      "license": "MIT",
      "description": "AutoEvals is a tool for quickly and easily evaluating AI model outputs using best practices.",
      "oss_fuzz_line_count": null,
      "oss_fuzz_line_cover_count": null
    },
    "dependency_graph": {
      "direct_count": 4,
      "transitive_count": 5,
      "vulnerable_direct": 0,
      "vulnerable_transitive": 0,
      "max_depth": 3
    },
    "slsa_attestation": false,
    "slsa_level": null,
    "fetched_at": "2026-01-12T08:07:56.190352Z",
    "sources_available": [
      "deps.dev:version",
      "deps.dev:dependencies",
      "deps.dev:project"
    ]
  },
  "analysis_summary": {
    "maintenance_status": "unknown",
    "security_summary": "No issues",
    "doc_summary": "",
    "concerns": [],
    "highlights": [
      "CI/CD configured"
    ],
    "forge_metrics": {
      "stars": 766,
      "forks": 50,
      "open_issues": 19
    },
    "dependency_count": 9
  },
  "analyzed_at": "2026-01-12T08:07:56.190890Z",
  "data_fetched_at": "2026-01-12T08:07:56.190892Z"
}